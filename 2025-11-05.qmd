---
title: "2025-11-05"
format:
  html: default
  pdf: default
params:
  course: "mc501"
  word_min: 450
  word_max: 500
  p2: 'Imagine you''re analyzing survey data and discover that some responses are missing or strangely formatted. You realize you could remove them, impute values, or rewrite categories to make things "fit." What would guide your decision-making in that situation? How does data cleaning impact the honesty and transparency of research?'
---

## Choose **one** prompt to answer

> **Prompt B:** `r params$p2`

---

## Response

<!-- RESPONSE-START -->
*Write your answer to **one** of the prompts here. Do not write anything else in this chapter.*
I think I would rearrange data to make things fit. First, I think this would help me personally to be organized because I do better when I see everything in front of me. Seeing all the data in front of me and correctly formatted would help me utilize every aspect of it, compared to isolating certain details because they do not fit correctly or are strangely formatted. Also, rewriting categories is a way to still find use for data. For all the work that I am doing in my research, I want to make sure that my data is all used and not just removed because of certain guidelines or formatting.  

My decision making would be guided by two things. The first would be my own personality and the way I work. The way I operate best is when things are organized and reformatting data, so everything is legible to me would help me operate best and therefore make the most ideal use of the data in front of me because I would be able to understand all of it well. Also, data efficiency would guide my decision making, As aforementioned, I would want to make sure I am using all the data I collect and not simply throwing away wealthy information because it does not fit into the other readings and discoveries.  

Of course, it is hard to say if this scenario happened and what kind of information I would be dealing with if it did happen. So, it is possible that the data is particularly outlandish that it might be more convenient for me to remove it. However, I would like to say I would try my best to maintain all the data and findings I received. If I had to remove data I would try to make it the most irrelevant data that was removed and make the categories fit to the other pieces of data that were not correctly aligned. 

As earlier mentioned, Data cleaning makes the data used efficient by filtering out strange data that does not align with the research. This filtering also helps researchers assure themselves that they are getting true and reliable data and removing that which is false and would obscure their findings. Going through your data and cleaning it assures that your research is transparent and allows fellow researchers to build upon your work. Without data cleaning, results can be misconstrued and lack integrity. Data cleaning is also a process where you select the data that you yourself are deeming true and that you as a personal researcher are standing by. This is why it is very crucial to correct misalignments and make sure things fit into categories, or even remove data, because if you keep incorrect data or do not data clean, you can end up standing by incorrect results and findings, which in turn is not helpful to anyone else wanting to build off of your data. Data cleaning not only affects you personally, but it also is a fact-check to similarly interested communities and correctly educating them on topics. 
<!-- RESPONSE-END -->

---

## Word Count & Range Check

```{r}
#| echo: false
#| message: false
#| warning: false
get_response_text <- function() {
  f <- knitr::current_input()
  if (is.null(f) || !file.exists(f)) return("")
  x <- readLines(f, warn = FALSE)
  # Find the lines that EXACTLY match the start/end markers
  s <- grep("^<!-- RESPONSE-START -->$", x)
  e <- grep("^<!-- RESPONSE-END -->$", x)
  if (length(s) != 1 || length(e) != 1 || e <= s) return("")
  paste(x[(s + 1L):(e - 1L)], collapse = "\n")
}
count_words <- function(txt) {
  # Remove code blocks and inline code before counting
  txt <- gsub("```[\\s\\S]*?```", " ", txt, perl = TRUE)
  txt <- gsub("`[^`]*`", " ", txt, perl = TRUE)
  # Keep letters, numbers, spaces, hyphens, and apostrophes
  txt <- gsub("[^\\p{L}\\p{N}\\s'-]", " ", txt, perl = TRUE)
  # Split by whitespace and count non-empty words
  words <- unlist(strsplit(txt, "\\s+", perl = TRUE))
  words <- words[nzchar(words)]
  length(words)
}
txt <- get_response_text()
n <- count_words(txt)
minw <- as.integer(params$word_min)
maxw <- as.integer(params$word_max)
in_range <- n >= minw && n <= maxw
cat(sprintf("**Word count:** %d  \n", n))
cat(sprintf("**Required range (%s):** %d–%d words  \n",
            toupper(params$course), minw, maxw))
cat(if (in_range) "**Status:** ✅ In range\n" else "**Status:** ❌ Out of range\n")
```
